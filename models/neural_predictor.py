# models/neural_predictor.py - Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ù…Ø­Ø³Ù†Ø© ÙˆØ§Ù„Ù…ØµØ­Ø­Ø©

import os
os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

import tensorflow as tf
import numpy as np
import logging
from typing import Dict, List, Tuple
import json
from datetime import datetime

class NeuralWeightPredictor:
    def __init__(self, input_dim: int = 30, hidden_layers: List[int] = [64, 32, 16]):
        self.input_dim = input_dim
        self.hidden_layers = hidden_layers
        self.model = None
        self.is_trained = False
        self.best_accuracy = 0.0
        self.training_history = None
        
        # Ø¥Ø¹Ø¯Ø§Ø¯ logging
        logging.basicConfig(level=logging.INFO)
        self.logger = logging.getLogger(__name__)
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬
        self.output_dir = "output/training/models"
        os.makedirs(self.output_dir, exist_ok=True)
        
        self._build_model()
    
    def _build_model(self):
        """Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø¹ØµØ¨ÙŠ Ù…Ø¹ Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬ Ø§Ù„ØµØ­ÙŠØ­"""
        try:
            self.logger.info("ğŸ—ï¸ Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø¹ØµØ¨ÙŠ...")
            
            model = tf.keras.Sequential()
            
            # Ø·Ø¨Ù‚Ø© Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„
            model.add(tf.keras.layers.Dense(self.hidden_layers[0], activation='relu', input_shape=(self.input_dim,)))
            model.add(tf.keras.layers.Dropout(0.2))
            
            # Ø§Ù„Ø·Ø¨Ù‚Ø§Øª Ø§Ù„Ù…Ø®ÙÙŠØ©
            for units in self.hidden_layers[1:]:
                model.add(tf.keras.layers.Dense(units, activation='relu'))
                model.add(tf.keras.layers.Dropout(0.2))
            
            # Ø·Ø¨Ù‚Ø© Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬ - Ø¥ØµÙ„Ø§Ø­: 3 ÙˆØ­Ø¯Ø§Øª Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† 15 Ù„ØªØ·Ø§Ø¨Ù‚ Ø´ÙƒÙ„ Ø§Ù„Ù‡Ø¯Ù
            model.add(tf.keras.layers.Dense(3, activation='softmax'))
            
            # ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
            model.compile(
                optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
                loss='categorical_crossentropy',
                metrics=['accuracy', tf.keras.metrics.CosineSimilarity()]
            )
            
            self.model = model
            self.logger.info("âœ… ØªÙ… Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø¹ØµØ¨ÙŠ Ø¨Ù†Ø¬Ø§Ø­")
            
        except Exception as e:
            self.logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¨Ù†Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {e}")
            raise
    
    def _prepare_data(self, training_data: List[Dict]) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:
        """ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ØªØ¯Ø±ÙŠØ¨"""
        try:
            X = []
            y = []
            
            for match in training_data:
                # Ø¯Ù…Ø¬ Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³ ÙÙŠ Ù…ØªØ¬Ù‡ ÙˆØ§Ø­Ø¯
                team_features = list(match['team_metrics'].values())
                opponent_features = list(match['opponent_metrics'].values())
                context_features = list(match['context'].values()) if isinstance(match['context'], dict) else [match['context']]
                
                features = team_features + opponent_features + context_features
                # ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù„Ø·ÙˆÙ„ Ø§Ù„ØµØ­ÙŠØ­ ÙˆØ¥Ù…Ù„Ø§Ø¡ Ø¨Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„ØµÙØ±ÙŠØ© Ø¥Ø°Ø§ Ù„Ø²Ù… Ø§Ù„Ø£Ù…Ø±
                if len(features) < self.input_dim:
                    features.extend([0.0] * (self.input_dim - len(features)))
                else:
                    features = features[:self.input_dim]
                
                X.append(features)
                
                # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø¥Ù„Ù‰ Ù…ØªØ¬Ù‡ ÙˆØ§Ø­Ø¯-hot
                actual_result = match['actual_result']
                if isinstance(actual_result, dict) and 'home_goals' in actual_result:
                    home_goals = actual_result['home_goals']
                    away_goals = actual_result['away_goals']
                    
                    if home_goals > away_goals:
                        result_vector = [1, 0, 0]  # ÙÙˆØ² Home
                    elif home_goals < away_goals:
                        result_vector = [0, 1, 0]  # ÙÙˆØ² Away
                    else:
                        result_vector = [0, 0, 1]  # ØªØ¹Ø§Ø¯Ù„
                    
                    y.append(result_vector)
                else:
                    # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…ØªØ¬Ù‡ Ø§ÙØªØ±Ø§Ø¶ÙŠ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØºÙŠØ± ØµØ­ÙŠØ­Ø©
                    y.append([0.33, 0.33, 0.34])
            
            X = np.array(X)
            y = np.array(y)
            
            # ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
            split_idx = int(0.8 * len(X))
            X_train, X_val = X[:split_idx], X[split_idx:]
            y_train, y_val = y[:split_idx], y[split_idx:]
            
            self.logger.info(f"ğŸ“Š Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨: {X_train.shape[0]} Ø¹ÙŠÙ†Ø©ØŒ Ø§Ù„ØªØ­Ù‚Ù‚: {X_val.shape[0]} Ø¹ÙŠÙ†Ø©")
            return X_train, y_train, X_val, y_val
            
        except Exception as e:
            self.logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ø¶ÙŠØ± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {e}")
            raise
    
    def train(self, training_data: List[Dict], epochs: int = 100):
        try:
            # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù„Ù‰ ØªÙ†Ø³ÙŠÙ‚ Ø±Ù‚Ù…ÙŠ Ù…Ù†Ø§Ø³Ø¨
            X = []
            y = []
            
            for match in training_data:
                try:
                    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ø±Ù‚Ù…ÙŠØ© ÙÙ‚Ø·
                    features = self._extract_numeric_features(match)
                    if features and len(features) == len(self._get_feature_names()):
                        X.append(features)
                        
                        # Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù…Ø³ØªÙ‡Ø¯ÙØ©
                        actual = match.get('actual_result', {})
                        home_goals = actual.get('home_goals', 0)
                        away_goals = actual.get('away_goals', 0)
                        
                        # ØªØ±Ù…ÙŠØ² Ø§Ù„Ù†ØªÙŠØ¬Ø© (ÙÙˆØ²/ØªØ¹Ø§Ø¯Ù„/Ø®Ø³Ø§Ø±Ø©)
                        if home_goals > away_goals:
                            y.append([1, 0, 0])  # ÙÙˆØ² Ø§Ù„Ù…Ù†Ø²Ù„
                        elif away_goals > home_goals:
                            y.append([0, 0, 1])  # ÙÙˆØ² Ø§Ù„Ø¶ÙŠÙ
                        else:
                            y.append([0, 1, 0])  # ØªØ¹Ø§Ø¯Ù„
                except Exception as e:
                    continue
            
            if len(X) < 10:
                self.logger.error("âŒ Ø¨ÙŠØ§Ù†Ø§Øª ØªØ¯Ø±ÙŠØ¨ ØºÙŠØ± ÙƒØ§ÙÙŠØ©")
                return False
            
            # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ numpy arrays Ù…Ø¹ Ø£Ù†ÙˆØ§Ø¹ Ø¨ÙŠØ§Ù†Ø§Øª ØµØ­ÙŠØ­Ø©
            X = np.array(X, dtype=np.float32)
            y = np.array(y, dtype=np.float32)
            
            # Ø§Ù„ØªØ¯Ø±ÙŠØ¨
            history = self.model.fit(
                X, y, 
                epochs=epochs, 
                validation_split=0.2,
                verbose=0,
                batch_size=32
            )
            
            self.is_trained = True
            self.training_history = history.history
            self.best_accuracy = max(history.history['accuracy'])
            
            # Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆØ§Ù„Ù†ØªØ§Ø¦Ø¬
            self.save_training_results()
            
            self.logger.info(f"âœ… ØªÙ… Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¨Ø¯Ù‚Ø© {self.best_accuracy:.2%}")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ø¹ØµØ¨ÙŠ: {e}")
            return False

    def _extract_numeric_features(self, match_data: Dict) -> List[float]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ø±Ù‚Ù…ÙŠØ© ÙÙ‚Ø·"""
        features = []
        
        # Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„ÙØ±ÙŠÙ‚
        team_metrics = match_data.get('team_metrics', {})
        opponent_metrics = match_data.get('opponent_metrics', {})
        
        numeric_metrics = [
            'points_per_match', 'win_rate', 'goal_difference',
            'goals_per_match', 'conceded_per_match', 'current_form',
            'home_advantage', 'defensive_efficiency'
        ]
        
        for metric in numeric_metrics:
            features.append(float(team_metrics.get(metric, 0.0)))
            features.append(float(opponent_metrics.get(metric, 0.0)))
        
        return features
    
    def _get_feature_names(self) -> List[str]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù…ÙŠØ²Ø§Øª"""
        numeric_metrics = [
            'points_per_match', 'win_rate', 'goal_difference',
            'goals_per_match', 'conceded_per_match', 'current_form',
            'home_advantage', 'defensive_efficiency'
        ]
        
        feature_names = []
        for metric in numeric_metrics:
            feature_names.append(f"team_{metric}")
            feature_names.append(f"opponent_{metric}")
        
        return feature_names
    
    def save_training_results(self):
        """Ø­ÙØ¸ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ¯Ø±ÙŠØ¨"""
        try:
            # Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
            model_path = f"{self.output_dir}/neural_model_{datetime.now().strftime('%Y%m%d_%H%M%S')}.keras"
            self.model.save(model_path, save_format='keras')
            
            # Ø­ÙØ¸ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨
            training_info = {
                'best_accuracy': self.best_accuracy,
                'training_history': self.training_history,
                'model_architecture': {
                    'input_dim': self.input_dim,
                    'hidden_layers': self.hidden_layers
                },
                'feature_names': self._get_feature_names(),
                'saved_at': datetime.now().isoformat()
            }
            
            info_path = model_path.replace('.keras', '_info.json')
            with open(info_path, 'w', encoding='utf-8') as f:
                json.dump(training_info, f, indent=2, ensure_ascii=False)
            
            self.logger.info(f"ğŸ’¾ ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆØ§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙŠ: {model_path}")
            
        except Exception as e:
            self.logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø­ÙØ¸ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ¯Ø±ÙŠØ¨: {e}")
    
    def predict_weights(self, team_metrics: Dict, opponent_metrics: Dict, context: Dict) -> Dict[str, float]:
        """ØªÙˆÙ‚Ø¹ Ø§Ù„Ø£ÙˆØ²Ø§Ù† Ø§Ù„Ù…Ø«Ù„Ù‰ Ù„Ù„Ù…Ù‚Ø§ÙŠÙŠØ³"""
        try:
            if not self.is_trained:
                self.logger.warning("âš ï¸  Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ØºÙŠØ± Ù…Ø¯Ø±Ø¨ØŒ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø£ÙˆØ²Ø§Ù† Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ©")
                return self.get_default_weights()
            
            # ØªØ­Ø¶ÙŠØ± Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„
            team_features = list(team_metrics.values())
            opponent_features = list(opponent_metrics.values())
            context_features = list(context.values()) if isinstance(context, dict) else [context]
            
            features = team_features + opponent_features + context_features
            
            # Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù…ÙŠØ²Ø§Øª Ù†Ø§Ù‚ØµØ©ØŒ Ø£Ø¶Ù Ø£ØµÙØ§Ø±
            if len(features) < self.input_dim:
                features.extend([0.0] * (self.input_dim - len(features)))
            else:
                features = features[:self.input_dim]
            
            X = np.array([features])
            
            # Ø§Ù„ØªÙ†Ø¨Ø¤
            predictions = self.model.predict(X, verbose=0)[0]
            
            # ØªØ­ÙˆÙŠÙ„ ØªÙ†Ø¨Ø¤Ø§Øª Ø§Ù„ÙÙˆØ²/Ø§Ù„Ø®Ø³Ø§Ø±Ø©/Ø§Ù„ØªØ¹Ø§Ø¯Ù„ Ø¥Ù„Ù‰ Ø£ÙˆØ²Ø§Ù† Ù„Ù„Ù…Ù‚Ø§ÙŠÙŠØ³
            # Ù†Ø³ØªØ®Ø¯Ù… Ù†Ù…Ø·Ø§Ù‹ Ø¨Ø³ÙŠØ·Ø§Ù‹: Ø¹Ù†Ø¯Ù…Ø§ ÙŠÙƒÙˆÙ† ØªÙ†Ø¨Ø¤ Ø§Ù„ÙÙˆØ² Ù…Ø±ØªÙØ¹Ø§Ù‹ØŒ Ù†Ø¹Ø·ÙŠ Ø£ÙˆØ²Ø§Ù†Ø§Ù‹ Ø£Ø¹Ù„Ù‰ Ù„Ù„Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ù‡Ø¬ÙˆÙ…ÙŠØ©
            win_prob, loss_prob, draw_prob = predictions
            
            # Ø¥Ù†Ø´Ø§Ø¡ Ø£ÙˆØ²Ø§Ù† Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ø­ØªÙ…Ø§Ù„Ø§Øª Ø§Ù„Ù†ØªÙŠØ¬Ø©
            weights = {}
            
            # Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ù‡Ø¬ÙˆÙ…ÙŠØ© (ØªØ±ØªØ¨Ø· Ø¨Ø§Ø­ØªÙ…Ø§Ù„ Ø§Ù„ÙÙˆØ²)
            offensive_metrics = ['goals_per_match', 'shot_efficiency', 'conversion_rate', 'points_per_match']
            for metric in offensive_metrics:
                if metric in team_metrics:
                    weights[metric] = win_prob * 0.3
            
            # Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ø¯ÙØ§Ø¹ÙŠØ© (ØªØ±ØªØ¨Ø· Ø¨Ø§Ø­ØªÙ…Ø§Ù„ Ø§Ù„Ø®Ø³Ø§Ø±Ø©)
            defensive_metrics = ['conceded_per_match', 'defensive_efficiency', 'goal_difference']
            for metric in defensive_metrics:
                if metric in team_metrics:
                    weights[metric] = (1 - loss_prob) * 0.2
            
            # Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ø¹Ø§Ù…Ø©
            general_metrics = ['win_rate', 'current_form', 'motivation_factor']
            for metric in general_metrics:
                if metric in team_metrics:
                    weights[metric] = 0.1 + (win_prob - loss_prob) * 0.1
            
            # Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³ Ø§Ù„Ø³ÙŠØ§Ù‚ÙŠØ©
            context_metrics = ['home_advantage', 'match_importance', 'historical_performance']
            for metric in context_metrics:
                if metric in context:
                    weights[metric] = 0.05 + draw_prob * 0.1
            
            # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³ Ù„Ù‡Ø§ Ù‚ÙŠÙ…
            all_metrics = set(team_metrics.keys()) | set(context.keys())
            for metric in all_metrics:
                if metric not in weights:
                    weights[metric] = 0.05
            
            # ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ø£ÙˆØ²Ø§Ù†
            total = sum(weights.values())
            if total > 0:
                weights = {k: v/total for k, v in weights.items()}
            else:
                weights = self.get_default_weights()
            
            return weights
            
        except Exception as e:
            self.logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªÙ†Ø¨Ø¤: {e}")
            return self.get_default_weights()
    
    def get_default_weights(self) -> Dict[str, float]:
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø£ÙˆØ²Ø§Ù† Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ©"""
        default_weights = {
            'points_per_match': 0.15,
            'win_rate': 0.12,
            'goal_difference': 0.10,
            'goals_per_match': 0.10,
            'conceded_per_match': 0.10,
            'shot_efficiency': 0.08,
            'conversion_rate': 0.08,
            'defensive_efficiency': 0.08,
            'current_form': 0.07,
            'motivation_factor': 0.06,
            'home_advantage': 0.03,
            'match_importance': 0.02,
            'historical_performance': 0.01
        }
        
        # ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ø£ÙˆØ²Ø§Ù†
        total = sum(default_weights.values())
        return {k: v/total for k, v in default_weights.items()}
    
    def save_model(self, filepath: str):
        """Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø¯Ø±Ø¨"""
        try:
            if self.is_trained and self.model:
                # Ø§Ø³ØªØ®Ø¯Ø§Ù… formato Keras Ø§Ù„Ø­Ø¯ÙŠØ«
                if filepath.endswith('.h5'):
                    filepath = filepath.replace('.h5', '.keras')
                
                self.model.save(filepath, save_format='keras')
                self.logger.info(f"ğŸ’¾ ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙÙŠ: {filepath}")
                
                # Ø­ÙØ¸ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨
                training_info = {
                    'best_accuracy': self.best_accuracy,
                    'training_history': self.training_history,
                    'saved_at': datetime.now().isoformat(),
                    'input_dim': self.input_dim,
                    'hidden_layers': self.hidden_layers
                }
                
                info_path = filepath.replace('.keras', '_info.json')
                with open(info_path, 'w', encoding='utf-8') as f:
                    json.dump(training_info, f, indent=2, ensure_ascii=False)
                    
        except Exception as e:
            self.logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {e}")
    
    def load_model(self, filepath: str):
        """ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø¯Ø±Ø¨ Ù…Ø¹ Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ø´ÙƒÙ„Ø© optimizer"""
        try:
            # Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨Ø¯ÙˆÙ† optimizer
            self.model = tf.keras.models.load_model(filepath, compile=False)
            
            # Ø¥Ø¹Ø§Ø¯Ø© ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ø¹ optimizer Ø¬Ø¯ÙŠØ¯
            self.model.compile(
                optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
                loss='categorical_crossentropy',
                metrics=['accuracy', tf.keras.metrics.CosineSimilarity()]
            )
            
            self.is_trained = True
            
            # ØªØ­Ù…ÙŠÙ„ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨
            info_path = filepath.replace('.keras', '_info.json').replace('.h5', '_info.json')
            if os.path.exists(info_path):
                with open(info_path, 'r') as f:
                    training_info = json.load(f)
                    self.best_accuracy = training_info.get('best_accuracy', 0.5)
                    self.training_history = training_info.get('training_history', {})
            
            self.logger.info(f"ğŸ“‚ ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ù†: {filepath}")
            
        except Exception as e:
            self.logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬: {e}")